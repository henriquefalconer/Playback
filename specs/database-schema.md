# Database Schema Specification

**Component:** SQLite Database Schema
**Version:** 1.0
**Last Updated:** 2026-02-07

## Overview

Playback uses SQLite for storing metadata about video segments and app activity. The database is lightweight, serverless, and well-suited for local storage of structured data.

## Database File

**Location:** `~/Library/Application Support/Playback/data/meta.sqlite3`

**Size:** Typically 10-50 MB (depends on recording duration)

**Format:** SQLite 3

**Encoding:** UTF-8

## Schema Version

**Current Version:** 1.0

**Version Table:**
```sql
CREATE TABLE IF NOT EXISTS schema_version (
    version TEXT PRIMARY KEY,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INSERT INTO schema_version (version) VALUES ('1.0');
```

## Tables

### segments

**Purpose:** Store metadata for each video segment

**Schema:**
```sql
CREATE TABLE IF NOT EXISTS segments (
    id TEXT PRIMARY KEY,           -- Segment ID (20-char hex string)
    date TEXT NOT NULL,             -- ISO date (YYYY-MM-DD)
    start_ts REAL NOT NULL,         -- Start timestamp (epoch seconds)
    end_ts REAL NOT NULL,           -- End timestamp (epoch seconds)
    frame_count INTEGER NOT NULL,   -- Number of frames in segment
    fps REAL,                       -- Video framerate (30.0)
    width INTEGER,                  -- Video width in pixels
    height INTEGER,                 -- Video height in pixels
    file_size_bytes INTEGER NOT NULL, -- Size of .mp4 file
    video_path TEXT NOT NULL        -- Relative path from base dir
);
```

**Indexes:**
```sql
CREATE INDEX IF NOT EXISTS idx_segments_date ON segments(date);
CREATE INDEX IF NOT EXISTS idx_segments_start_ts ON segments(start_ts);
CREATE INDEX IF NOT EXISTS idx_segments_end_ts ON segments(end_ts);
```

**Example Row:**
```sql
INSERT INTO segments (
    id, date, start_ts, end_ts, frame_count, fps, width, height, file_size_bytes, video_path
) VALUES (
    'a3f8b29c4d1e5f67890a',
    '2025-12-22',
    1703258400.0,
    1703258700.0,
    150,
    30.0,
    3840,
    2160,
    2359296,
    'chunks/202512/22/a3f8b29c4d1e5f67890a.mp4'
);
```

**Field Descriptions:**

- **id:** Unique identifier, generated by `os.urandom(10).hex()` (20 hex chars)
- **date:** Human-readable date for grouping and queries
- **start_ts:** Timestamp of first frame (from `st_birthtime` or `mtime`)
- **end_ts:** Timestamp of last frame
- **frame_count:** Number of screenshots combined into this segment
- **fps:** Video framerate (always 30.0 in current implementation)
- **width, height:** Video dimensions (may vary if display resolution changed)
- **file_size_bytes:** Used for storage usage calculations
- **video_path:** Relative path from data directory (portable)

### appsegments

**Purpose:** Store timeline of app activity (which app was frontmost when)

**Schema:**
```sql
CREATE TABLE IF NOT EXISTS appsegments (
    id TEXT PRIMARY KEY,           -- App segment ID (20-char hex string)
    app_id TEXT,                   -- Bundle identifier (e.g., com.apple.Safari)
    date TEXT NOT NULL,             -- ISO date (YYYY-MM-DD)
    start_ts REAL NOT NULL,         -- Start timestamp (epoch seconds)
    end_ts REAL NOT NULL            -- End timestamp (epoch seconds)
);
```

**Indexes:**
```sql
CREATE INDEX IF NOT EXISTS idx_appsegments_date ON appsegments(date);
CREATE INDEX IF NOT EXISTS idx_appsegments_app_id ON appsegments(app_id);
CREATE INDEX IF NOT EXISTS idx_appsegments_start_ts ON appsegments(start_ts);
CREATE INDEX IF NOT EXISTS idx_appsegments_end_ts ON appsegments(end_ts);
```

**Example Rows:**
```sql
INSERT INTO appsegments (id, app_id, date, start_ts, end_ts) VALUES
    ('b4f9c30d1e2a5f678901', 'com.apple.Safari', '2025-12-22', 1703258400.0, 1703259000.0),
    ('c5g0d41e2f3b6g789012', 'com.apple.Xcode', '2025-12-22', 1703259000.0, 1703260200.0),
    ('d6h1e52f3g4c7h890123', 'com.apple.Safari', '2025-12-22', 1703260200.0, 1703261000.0);
```

**Field Descriptions:**

- **id:** Unique identifier (same generation as segments)
- **app_id:** Bundle identifier of frontmost app (nullable for "unknown")
- **date:** Human-readable date for grouping
- **start_ts:** When this app became frontmost
- **end_ts:** When this app lost focus or day ended

**Relationship to segments:**
- Independent timelines (appsegments may span multiple segments or partial segments)
- Used for timeline visualization (color-coded by app)
- No foreign key constraints (appsegments can exist without corresponding segments)

## Queries

### Playback App Queries

**Load all segments (on launch):**
```sql
SELECT id, start_ts, end_ts, frame_count, fps, video_path
FROM segments
ORDER BY start_ts ASC;
```

**Load all app segments (for timeline colors):**
```sql
SELECT id, app_id, start_ts, end_ts
FROM appsegments
ORDER BY start_ts ASC;
```

**Find segment for specific timestamp:**
```sql
SELECT id, start_ts, end_ts, frame_count, fps, video_path
FROM segments
WHERE start_ts <= ? AND end_ts >= ?
LIMIT 1;
```

**Get latest timestamp:**
```sql
SELECT MAX(end_ts) FROM segments;
```

### Processing Service Queries

**Check if segment already exists (avoid duplicates):**
```sql
SELECT id FROM segments WHERE id = ?;
```

**Insert segment:**
```sql
INSERT OR REPLACE INTO segments (
    id, date, start_ts, end_ts, frame_count, fps, width, height, file_size_bytes, video_path
) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
```

**Insert app segment:**
```sql
INSERT OR REPLACE INTO appsegments (
    id, app_id, date, start_ts, end_ts
) VALUES (?, ?, ?, ?, ?);
```

**Find segments older than cutoff (for cleanup):**
```sql
SELECT id, video_path FROM segments WHERE start_ts < ?;
```

**Delete old segments:**
```sql
DELETE FROM segments WHERE id = ?;
DELETE FROM appsegments WHERE id = ?;
```

### Analytics Queries (Future)

**Total recording time:**
```sql
SELECT SUM(end_ts - start_ts) / 3600.0 AS hours FROM segments;
```

**Recording time by date:**
```sql
SELECT date, SUM(end_ts - start_ts) / 3600.0 AS hours
FROM segments
GROUP BY date
ORDER BY date DESC;
```

**Most used apps:**
```sql
SELECT app_id, SUM(end_ts - start_ts) / 3600.0 AS hours
FROM appsegments
WHERE app_id IS NOT NULL
GROUP BY app_id
ORDER BY hours DESC
LIMIT 10;
```

**Storage usage by date:**
```sql
SELECT date, SUM(file_size_bytes) / (1024.0 * 1024.0 * 1024.0) AS gb
FROM segments
GROUP BY date
ORDER BY date DESC;
```

## Database Initialization

**Function:**
```python
def init_meta_db(path: Path) -> None:
    """Create tables if they don't exist."""
    conn = sqlite3.connect(path)
    try:
        cur = conn.cursor()

        # Schema version table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS schema_version (
                version TEXT PRIMARY KEY,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # Segments table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS segments (
                id TEXT PRIMARY KEY,
                date TEXT NOT NULL,
                start_ts REAL NOT NULL,
                end_ts REAL NOT NULL,
                frame_count INTEGER NOT NULL,
                fps REAL,
                width INTEGER,
                height INTEGER,
                file_size_bytes INTEGER NOT NULL,
                video_path TEXT NOT NULL
            )
        """)

        # App segments table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS appsegments (
                id TEXT PRIMARY KEY,
                app_id TEXT,
                date TEXT NOT NULL,
                start_ts REAL NOT NULL,
                end_ts REAL NOT NULL
            )
        """)

        # Indexes
        cur.execute("CREATE INDEX IF NOT EXISTS idx_segments_date ON segments(date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_segments_start_ts ON segments(start_ts)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_segments_end_ts ON segments(end_ts)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_appsegments_date ON appsegments(date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_appsegments_app_id ON appsegments(app_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_appsegments_start_ts ON appsegments(start_ts)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_appsegments_end_ts ON appsegments(end_ts)")

        # Insert schema version
        cur.execute("""
            INSERT OR IGNORE INTO schema_version (version) VALUES ('1.0')
        """)

        conn.commit()
    finally:
        conn.close()
```

## Database Migrations

### Migration Strategy

**Version Check:**
```python
def get_schema_version() -> str:
    conn = sqlite3.connect(META_DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute("SELECT version FROM schema_version ORDER BY applied_at DESC LIMIT 1")
        row = cur.fetchone()
        return row[0] if row else "unknown"
    except sqlite3.OperationalError:
        # Table doesn't exist (very old version or corrupt)
        return "0.0"
    finally:
        conn.close()
```

**Migration Example (1.0 â†’ 1.1):**
```python
def migrate_1_0_to_1_1():
    """Add new column to segments table."""
    conn = sqlite3.connect(META_DB_PATH)
    try:
        cur = conn.cursor()

        # Add new column (example: codec)
        cur.execute("ALTER TABLE segments ADD COLUMN codec TEXT DEFAULT 'h264'")

        # Update schema version
        cur.execute("INSERT INTO schema_version (version) VALUES ('1.1')")

        conn.commit()
        print("[Migration] Successfully migrated from 1.0 to 1.1")
    except sqlite3.OperationalError as e:
        print(f"[Migration] Failed: {e}")
    finally:
        conn.close()
```

## Database Maintenance

### Vacuum

**Purpose:** Reclaim space from deleted rows

**Frequency:** Monthly or after large cleanup

**Command:**
```sql
VACUUM;
```

**Implementation:**
```python
def vacuum_database():
    conn = sqlite3.connect(META_DB_PATH)
    conn.execute("VACUUM")
    conn.close()
```

### Integrity Check

**Purpose:** Verify database is not corrupt

**Command:**
```sql
PRAGMA integrity_check;
```

**Implementation:**
```python
def check_database_integrity() -> bool:
    conn = sqlite3.connect(META_DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute("PRAGMA integrity_check")
        result = cur.fetchone()[0]
        return result == "ok"
    finally:
        conn.close()
```

### Backup

**Purpose:** Create backup before major operations

**Implementation:**
```python
import shutil

def backup_database():
    backup_path = META_DB_PATH.with_suffix('.sqlite3.backup')
    shutil.copy2(META_DB_PATH, backup_path)
    print(f"[Database] Backed up to {backup_path}")
```

## Database Access Patterns

### Concurrency

**Readers:**
- Playback app (read-only)
- Processing service (write during processing)

**Writers:**
- Processing service only (single writer)

**Locking:**
- SQLite automatically handles locking
- WAL mode enables concurrent reads during writes

**Enable WAL Mode:**
```sql
PRAGMA journal_mode=WAL;
```

**Implementation:**
```python
conn = sqlite3.connect(META_DB_PATH)
conn.execute("PRAGMA journal_mode=WAL")
```

### Performance Optimization

**Connection Pooling (not needed):**
- Short-lived connections (open, query, close)
- No need for persistent connections

**Prepared Statements:**
```python
# Good: Reuse prepared statement
stmt = conn.cursor()
stmt.execute("INSERT INTO segments (id, ...) VALUES (?, ...)", values)

# Bad: Concatenate strings (SQL injection risk)
conn.execute(f"INSERT INTO segments VALUES ('{id}', ...)")
```

**Batch Inserts:**
```python
# Good: Single transaction for multiple inserts
conn = sqlite3.connect(META_DB_PATH)
cur = conn.cursor()
cur.executemany("INSERT INTO segments (...) VALUES (?, ...)", segment_data)
conn.commit()
conn.close()

# Bad: One transaction per insert
for segment in segments:
    conn = sqlite3.connect(META_DB_PATH)
    conn.execute("INSERT INTO segments (...) VALUES (?)", segment)
    conn.commit()
    conn.close()
```

## Testing

### Unit Tests

- Database initialization (create tables)
- Insert segment (valid data)
- Insert segment (duplicate ID, should replace)
- Query segments by date
- Query segments by timestamp range
- Delete old segments
- Vacuum database

### Integration Tests

- Concurrent reads (playback app while processing)
- Database corruption recovery
- Migration from old schema version

## Future Enhancements

### Potential Schema Changes

**Version 1.1:**
- Add `codec` column to segments (h264, hevc, av1)
- Add `bitrate` column to segments (for quality analysis)

**Version 2.0:**
- Add `thumbnails` table (store thumbnail images for timeline scrubbing)
- Add `bookmarks` table (user-saved interesting moments)
- Add `annotations` table (user notes on timeline)

### Additional Tables

**tags:**
```sql
CREATE TABLE tags (
    id TEXT PRIMARY KEY,
    segment_id TEXT NOT NULL,
    tag TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (segment_id) REFERENCES segments(id)
);
```

**bookmarks:**
```sql
CREATE TABLE bookmarks (
    id TEXT PRIMARY KEY,
    timestamp REAL NOT NULL,
    title TEXT,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**search_index:**
```sql
CREATE VIRTUAL TABLE search_index USING fts5(
    segment_id,
    text_content,  -- OCR'd text from screenshots
    content=segments
);
```
